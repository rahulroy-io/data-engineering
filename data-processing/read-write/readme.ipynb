{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Configurations\n",
    "\n",
    "1. **Application Configuration:**\n",
    "   - `spark_conf.set(\"spark.app.name\", \"YourAppName\")`: Can be changed dynamically.\n",
    "   - `spark_conf.set(\"spark.driver.memory\", \"2g\")`: Static, set before starting the Spark session.\n",
    "\n",
    "2. **Cluster Configuration:**\n",
    "   - `spark_conf.setMaster(\"spark://your-master-url\")`: Static, set before starting the Spark session.\n",
    "   - `spark_conf.set(\"spark.deploy.mode\", \"cluster\")`: Static, set before starting the Spark session.\n",
    "\n",
    "3. **Execution Configuration:**\n",
    "   - `spark_conf.set(\"spark.task.maxFailures\", \"3\")`: Can be changed dynamically.\n",
    "   - `spark_conf.set(\"spark.speculation\", \"true\")`: Can be changed dynamically.\n",
    "\n",
    "4. **Memory Configuration:**\n",
    "   - `spark_conf.set(\"spark.driver.memory\", \"1g\")`: Static, set before starting the Spark session.\n",
    "   - `spark_conf.set(\"spark.executor.memory\", \"4g\")`: Static, set before starting the Spark session.\n",
    "   - `spark_conf.set(\"spark.memory.fraction\", \"0.8\")`: Static, set before starting the Spark session.\n",
    "\n",
    "5. **Serialization and Compression:**\n",
    "   - `spark_conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")`: Static, set before starting the Spark session.\n",
    "   - `spark_conf.set(\"spark.io.compression.codec\", \"snappy\")`: Static, set before starting the Spark session.\n",
    "\n",
    "6. **External Dependencies:**\n",
    "   - `spark_conf.set(\"spark.jars.packages\", \"group:artifact:version\")`: Can be changed dynamically.\n",
    "\n",
    "7. **Spark SQL Configuration:**\n",
    "   - `spark_conf.set(\"spark.sql.shuffle.partitions\", \"200\")`: Can be changed dynamically.\n",
    "   - `spark_conf.set(\"spark.sql.catalogImplementation\", \"hive\")`: Static, set before starting the Spark session.\n",
    "\n",
    "8. **Delta Lake Configuration:**\n",
    "   - `spark_conf.set(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")`: Static, set before starting the Spark session.\n",
    "\n",
    "**Start Spark Session:**\n",
    "`spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()`\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
